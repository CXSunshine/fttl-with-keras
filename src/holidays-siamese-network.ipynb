{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, merge\n",
    "from keras.layers.core import Activation, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.misc import imresize\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\"\n",
    "IMAGE_DIR = os.path.join(DATA_DIR, \"holiday-photos\")\n",
    "\n",
    "RESIZE_WIDTH = 300\n",
    "RESIZE_HEIGHT = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data\n",
    "\n",
    "File naming conventions are as follows:\n",
    "\n",
    "* first 4 numbers of filename prefix refer to the group\n",
    "* next 2 numbers refer to the image in the group.\n",
    "\n",
    "For example: 100000.jpg and 100002.jpg are \"similar\", but 123700.jpg is \"different\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 0 pos + 0 neg = 0 total image triples\r",
      "Generated 300 pos + 300 neg = 600 total image triples\r",
      "Generated 1100 pos + 1100 neg = 2200 total image triples\r",
      "Generated 1800 pos + 1800 neg = 3600 total image triples\r",
      "Generated 2072 pos + 2072 neg = 4144 total image triples, COMPLETE\n",
      "2900 1244\n"
     ]
    }
   ],
   "source": [
    "def get_image_triples(image_dir):\n",
    "    \n",
    "    image_groups = {}\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        base_name = image_name[0:-4]\n",
    "        group_name = base_name[0:4]\n",
    "        if image_groups.has_key(group_name):\n",
    "            image_groups[group_name].append(image_name)\n",
    "        else:\n",
    "            image_groups[group_name] = [image_name]\n",
    "\n",
    "    num_sim = 0\n",
    "    image_triples = []\n",
    "    group_list = sorted(list(image_groups.keys()))\n",
    "    for i, g in enumerate(group_list):\n",
    "        if num_sim % 100 == 0:\n",
    "            print(\"Generated {:d} pos + {:d} neg = {:d} total image triples\"\n",
    "                  .format(num_sim, num_sim, 2*num_sim), end=\"\\r\")\n",
    "        images_in_group = image_groups[g]\n",
    "        # generate similar pairs\n",
    "        sim_pairs_it = itertools.combinations(images_in_group, 2)\n",
    "        # for each similar pair, generate a different pair\n",
    "        for ref_image, sim_image in sim_pairs_it:\n",
    "            image_triples.append((ref_image, sim_image, 1))\n",
    "            num_sim += 1\n",
    "            while True:\n",
    "                j = np.random.randint(low=0, high=len(group_list), size=1)[0]\n",
    "                if j != i: break\n",
    "            dif_image_candidates = image_groups[group_list[j]]\n",
    "            k = np.random.randint(low=0, high=len(dif_image_candidates), size=1)[0]\n",
    "            dif_image = dif_image_candidates[k]\n",
    "            image_triples.append((ref_image, dif_image, 0))\n",
    "        \n",
    "    print(\"Generated {:d} pos + {:d} neg = {:d} total image triples, COMPLETE\"\n",
    "          .format(num_sim, num_sim, 2*num_sim))\n",
    "    return image_triples\n",
    "\n",
    "\n",
    "triples = get_image_triples(IMAGE_DIR)\n",
    "triples_train, triples_test = train_test_split(triples, train_size=0.7)\n",
    "print(len(triples_train), len(triples_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cached_imread(image_path, image_cache):\n",
    "    if not image_cache.has_key(image_path):\n",
    "        image = plt.imread(image_path)\n",
    "        image = imresize(image, (RESIZE_WIDTH, RESIZE_HEIGHT))\n",
    "        image_cache[image_path] = image\n",
    "    return image_cache[image_path]\n",
    "\n",
    "def preprocess_images(image_names, seed, datagen, image_cache):\n",
    "    np.random.seed(seed)\n",
    "    X = np.zeros((len(image_names), RESIZE_WIDTH, RESIZE_HEIGHT, 3))\n",
    "    for i, image_name in enumerate(image_names):\n",
    "        image = cached_imread(os.path.join(IMAGE_DIR, image_name), image_cache)\n",
    "        X[i] = datagen.random_transform(image) / 255.0\n",
    "    return X\n",
    "\n",
    "def image_triple_generator(image_triples, batch_size):\n",
    "    datagen_args = dict(rotation_range=10,\n",
    "                        width_shift_range=0.2,\n",
    "                        height_shift_range=0.2,\n",
    "                        shear_range=0.2,\n",
    "                        zoom_range=0.2,\n",
    "                        horizontal_flip=True)\n",
    "    datagen_left = ImageDataGenerator(**datagen_args)\n",
    "    datagen_right = ImageDataGenerator(**datagen_args)\n",
    "    image_cache = {}\n",
    "    \n",
    "    while True:\n",
    "        # loop once per epoch\n",
    "        num_recs = len(image_triples)\n",
    "        indices = np.random.permutation(np.arange(num_recs))\n",
    "        num_batches = num_recs // batch_size\n",
    "        for bid in range(num_batches):\n",
    "            # loop once per batch\n",
    "            batch_indices = indices[bid * batch_size : (bid + 1) * batch_size]\n",
    "            batch = [image_triples[i] for i in batch_indices]\n",
    "            # make sure the two image data generators generate same transformations\n",
    "            seed = np.random.randint(low=0, high=1000, size=1)[0]\n",
    "            Xleft = preprocess_images([b[0] for b in batch], seed, datagen_left, image_cache)\n",
    "            Xright = preprocess_images([b[1] for b in batch], seed, datagen_right, image_cache)\n",
    "            Y = np_utils.to_categorical(np.array([b[2] for b in batch]))\n",
    "            yield [Xleft, Xright], Y\n",
    "            \n",
    "\n",
    "image_datagen = image_triple_generator(triples_train, 32)\n",
    "image_datagen_val = image_triple_generator(triples_train, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch = image_datagen.next()\n",
    "# batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_base_network(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode=\"same\", input_shape=input_shape))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution2D(256, 3, 3, border_mode=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    return model\n",
    "\n",
    "input_shape = (RESIZE_WIDTH, RESIZE_HEIGHT, 3)\n",
    "vectorizer = create_base_network(input_shape)\n",
    "input_left = Input(shape=input_shape)\n",
    "input_right = Input(shape=input_shape)\n",
    "\n",
    "vector_left = vectorizer(input_left)\n",
    "vector_right = vectorizer(input_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    x, y = vectors\n",
    "    return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
    "\n",
    "def euclidean_distance_output_shape(shapes):\n",
    "    shape_x, shape_y = shapes\n",
    "    return (shape_x[0], 1)\n",
    "\n",
    "distance = Lambda(euclidean_distance, \n",
    "                  output_shape=euclidean_distance_output_shape)([vector_left, vector_right])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(input=[input_left, input_right], output=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contrastive_loss(y, y_):\n",
    "    margin = 1\n",
    "    return K.mean(y - K.square(y_) + (1 - y) * K.square(K.maximum(margin - y_, 0)))\n",
    "\n",
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=os.path.join(DATA_DIR, \"holidays-siamese-best.h5\"),\n",
    "                            save_best_only=True)\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "num_train_samples = len(triples_train)\n",
    "num_val_samples = int(0.2 * num_train_samples)\n",
    "history = model.fit_generator(image_datagen, \n",
    "                              samples_per_epoch=num_train_samples,\n",
    "                              nb_epoch=NUM_EPOCHS,\n",
    "                              validation_data=image_datagen_val,\n",
    "                              nb_val_samples=num_val_samples,\n",
    "                              callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
